{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"XJBPK1a__Ioo"},"source":["# Building and training the MENACE"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rJbLQJya-H4o"},"source":["The Matchbox Educable Noughts and Crosses Engine (MENACE) is a tic-tac-toe playing machine learning algorithm developed by Donald Michie in 1961. The original MENACE was built as a mechanical computer made of 304 matchboxes and a set of rules for learning. This is a Python implementation of the same logic that I worked on as a problem solving and learning exercise.  \n","\n","- The project was inspired by this blogpost: [Underfitted, The Most Ridiculous Tic-Tac-Toe Machine](https://underfitted.svpino.com/p/the-most-ridiculous-tic-tac-toe-machine)  \n","- More info on the original MENACE can be found on [Wikipedia](https://en.wikipedia.org/wiki/Matchbox_Educable_Noughts_and_Crosses_Engine).  \n","- Finding the possible states of the game is not trivial. This part a solution was copied from this repo https://github.com/vug/tic-tac-toe-game-states-graph and studied in the notebook [MENACE_understanding_possible_board_states.ipynb](MENACE_understanding_possible_board_states.ipynb)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256},"executionInfo":{"elapsed":463,"status":"error","timestamp":1678870378263,"user":{"displayName":"Fredrik LÃ¶fman","userId":"16785637798508098627"},"user_tz":-120},"id":"GOQcIiJCbLhk","outputId":"c4b1ffff-d57a-40ae-c66e-6bdd94cab8f6"},"outputs":[],"source":["import import_ipynb\n","import random\n","import math\n","from itertools import chain"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#%load_ext ask_ai.magics"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Setting flush=True in print() to flush the output to the console immediately\n","# This is needed to achieve expected behaviour in interactive mode\n","import functools\n","print = functools.partial(print, flush=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We import the functions for game state and symmetry group analysis defined in [MENACE_board_states_functions.ipynb](MENACE_board_states_functions.ipynb)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["importing Jupyter notebook from MENACE_board_states_functions.ipynb\n"]}],"source":["from MENACE_board_states_functions import *"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Class and game play function definitions"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The TokenBag class represents the content within one matchbox in the engine.\n","For each of the nine position on the 3x3 board there are separate tokens. At the start of the \n","game each position has three corresponding tokens. As the engine learns the number of these tokens\n","changes."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class TokenBag:\n","    def __init__(self, start_tokens = 3):\n","        # Each board position is initialized with start_tokens numbers of tokens\n","        \n","        # dict keys represents board positions as below, values represent token count\n","        # 0, 1, 2\n","        # 3, 4, 5\n","        # 6, 7, 8\n","        \n","        board_dict = {}\n","        for i in range(9):\n","            board_dict[i] = start_tokens\n","    \n","        self.token_counts = board_dict\n","\n","    def __str__(self):\n","        return str(self.token_counts)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The MatchBoxes class represents the engine's 765 matchboxes, one for each possible\n","state of the game board. Each matchbox has a token bag and the information on what \n","board positions (symmetry group) the box represents.\n","\n","The class has two functions. get_token selects a random token from the box that is then used to play the next move in the game. change_token_count updates the number of tokens in the boxes TokenBag."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class MatchBoxes:\n","    # Class to represent the matchboxes used by the MENACE engine\n","    # Dictionary of boxes, where the key is the box number and the values are\n","    # a dictionary of tokens for each position 0-8 and a list of all states in symmetry group including duplicates.\n","    \n","    # Function that takes all_states as input and creates a dict with symmetry group number as key and \n","    # the first board state in the symmetry group as value. This state is used to calculate all other transformations.\n","\n","    def __init__(self):\n","        def tuple_state_to_dict(st):\n","            # Nested state tuple to list\n","            st_list = []\n","            pos = 0\n","            for i in st:\n","                for j in i:\n","                    st_list.append(pos)\n","                    pos += 1\n","                    st_list.append(j)\n","            # State list to dictionary\n","            it = iter(st_list)\n","            st_dict = dict(zip(it, it))\n","            return st_dict\n","        \n","        def set_box_values():\n","            new_dict = {}\n","            all_states = all_states_and_groups() # Dictionary with all possible states as keys and symmetry group number as value\n","            for key, value in all_states.items():\n","                if value not in new_dict:\n","                    new_dict[value] = [TokenBag(), [key]]\n","            \n","            # Add all symmetry states includeing duplicates to the list of states in each box\n","            for key, value in new_dict.items():\n","                canonical_state = value[1][0] # First state in symmetry group\n","                new_dict[key][1] = get_symmetries_with_duplicates(canonical_state) \n","                # Remove tokens from already played positions in canonical state\n","                board_state_dict = tuple_state_to_dict(new_dict[key][1][0])\n","                for pos in board_state_dict:\n","                    if board_state_dict[pos] != 0:\n","                        new_dict[key][0].token_counts[pos] = 0               \n","            return new_dict\n","    \n","        self.boxes = set_box_values()\n","    \n","    def get_token(self, board_state):\n","        board_position_symmetries = get_symmetries_with_duplicates(((0,1,2),(3,4,5),(6,7,8)))\n","        all_states = all_states_and_groups() # Dictionary with all possible states as keys and symmetry group number as value\n","        # If the board state is not in all_states, return\n","        if board_state not in all_states:\n","            print('ERROR: Board state not among allowed states.')\n","            print_state(board_state)\n","            return\n","        # Transform the board_state tuple to a dictionary\n","        def tuple_state_to_dict(st):\n","            # Nested state tuple to list\n","            st_list = []\n","            pos = 0\n","            for i in st:\n","                for j in i:\n","                    st_list.append(pos)\n","                    pos += 1\n","                    st_list.append(j)\n","            # State list to dictionary\n","            it = iter(st_list)\n","            st_dict = dict(zip(it, it))\n","            return st_dict\n","\n","        # Get the box number corresponding to the given board state\n","        box_number = all_states[board_state]\n","        # Get the box corresponding to the box number\n","        box = self.boxes[box_number]\n","        \n","        # Get the total number of tokens in the box\n","        total_tokens = sum(box[0].token_counts.values()) # box[0] is the TokenBag object\n","        # If the TokenBag is empty, create a new TokenBag\n","        if total_tokens == 0:\n","            box[0] = TokenBag()\n","            board_state_dict = tuple_state_to_dict(box[1][0]) #box[1][0] is the first state in the symmetry group\n","            for pos in board_state_dict:\n","                if board_state_dict[pos] != 0:\n","                    box[0].token_counts[pos] = 0\n","\n","            total_tokens = sum(box[0].token_counts.values())\n","\n","        # Select a random number between 1 and the total number of tokens\n","        try:\n","            random_number = random.randint(1, total_tokens)\n","        except ValueError:\n","            print(f'ERROR: No tokens in box {box_number}. {box[0].token_counts}')\n","            return\n","        # Initialize a variable to keep track of the number of tokens counted\n","        tokens_counted = 0\n","        # Loop through the token counts for the box\n","        for position, count in box[0].token_counts.items():\n","            # Add the token count to the token count variable\n","            tokens_counted += count\n","            # If the random number is less than or equal to the token count,\n","            # return the position\n","            if random_number <= tokens_counted:\n","                chosen_token = position\n","                break\n","\n","        # Get the (first) index of the symmetry state\n","        symmetry_state_index = box[1].index(board_state) # box[1] is the list of symmetry states\n","        # Specific board position symmetry to dict\n","        board_position_symmetry_dict = tuple_state_to_dict(board_position_symmetries[symmetry_state_index])\n","        # Get the position of the chosen token in the symmetry state\n","        #symmetry_position = board_position_symmetry_dict[chosen_token]\n","        symmetry_position = [k for k, v in board_position_symmetry_dict.items() if v == chosen_token][0]\n","        \n","\n","        return box_number, chosen_token, symmetry_position #chosen_token for positions played book keeping and symmetry_position to update board state\n","    \n","\n","\n","    def change_token_count(self, box_number, position, change):\n","        # Change the token count for a given box and position\n","        self.boxes[box_number][0].token_counts[position] += change\n","\n","    def show_token_bag(self, box_number):\n","        # Show the token bag for a given box\n","        print(self.boxes[box_number][0])\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The MenaceEngine is the class that represents the learning MENACE engine. It has a MatchBoxes object from which it selects the moves to play and methods for playing moves and updating the state of the TokenBags in the match boxes. TokenBags are updated while the MenaceEngine is learning. The engine is learning by default and this can be changed using the set_learning method."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# A class that represents the learning MENACE engine\n","class MenaceEngine:\n","    '''\n","    A class that represents the MENACE learning engine.\n","    There are 765 symmetry states represented by matchboxes, one for each possible board state.\n","    \n","    https://en.wikipedia.org/wiki/Matchbox_Educable_Noughts_and_Crosses_Engine\n","    Once the game was finished, if MENACE had won, it would then receive a \"reward\" for its victory. \n","    The removed beads showed the sequence of the winning moves.[15] These were returned to their respective trays, \n","    easily identifiable since they were slightly open, as well as three bonus beads of the same colour.[11] \n","    In this way, in future games MENACE would become more likely to repeat those winning moves, \n","    reinforcing winning strategies. If it lost, the removed beads were not returned, \"punishing\" MENACE, \n","    and meaning that in future it would be less likely, and eventually incapable if that colour of bead became absent, \n","    to repeat the moves that cause a loss.[3][8] If the game was a draw, one additional bead was added to each box.[11]\n","    \n","    # Unclear how many beads are in the boxes in the beginning\n","    '''\n","    \n","    def __init__(self, name):\n","        # MenaceEngine is initialized with one MatchBoxes object\n","        self.boxes = MatchBoxes()\n","        # Initialize a list to keep track of the played positions\n","        self.played_positions = []\n","        # Initialize a variable to keep track of the learning status of the MENACE engine\n","        self.is_learning = True\n","        self.name = name\n","\n","    # Method that selects a random token from a box corresponding to a given board state, saves the played position\n","    # to a list and returns the position\n","    def play(self, board_state):\n","        # Call boxes.get_token(board_state) --> (box_number, chosen_token, symmetry_position)\n","        box_number, chosen_token, symmetry_position = self.boxes.get_token(board_state)\n","        # Add box_number and chosen_token to played_positions\n","        self.played_positions.append((box_number, chosen_token))\n","        # Return symmetry_position as the position to play\n","        return symmetry_position\n","        \n","    \n","    # Method that resolves the game and updates the matchboxes if the MENACE engine is learning\n","    def resolve_game(self, result):\n","        # If the MENACE engine is not learning, return\n","        if not self.is_learning:\n","            self.played_positions = []\n","            return\n","        # If the result is Win, add three additional tokens to each box in played_positions\n","        if result == 'W':\n","            for box_number, position in self.played_positions:\n","                self.boxes.change_token_count(box_number, position, 3)\n","        # If the result is Loss, remove one token from each box in played_positions\n","        elif result == 'L':\n","            for box_number, position in self.played_positions:\n","                self.boxes.change_token_count(box_number, position, -1)\n","        # If the result is Draw, add one additional token to each box in played_positions\n","        elif result == 'D':\n","            for box_number, position in self.played_positions:\n","                self.boxes.change_token_count(box_number, position, 1)\n","        # Reset played_positions\n","        self.played_positions = []\n","\n","    # Method to set the learning status of the MENACE engine\n","    def set_learning(self, is_learning):\n","        self.is_learning = is_learning\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The play_game function plays a game between two players. The function prints the moves if to_print is set to True."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# A function that plays a game of noughts and crosses between two players\n","def play_game(playerA, playerB, to_print = True, to_return_winner = False):\n","    \n","    # Select a random player to start the game\n","    if random.randint(0, 1) == 0:\n","        player1, player2 = playerA, playerB\n","    else:\n","        player1, player2 = playerB, playerA\n","    \n","    board_state = ((0, 0, 0), (0, 0, 0), (0, 0, 0))\n","    is_game_over = False\n","    winner = None\n","    turn = 0\n","    to_print = to_print\n","\n","    # Helper functions to work with the board state\n","    # Tuple is immutable, so we need to convert it to a list to update it\n","    # Tuples are used as keys in the all_states dictionary\n","    def tuple_state_to_list(st):\n","        l = []\n","        for t in st:\n","            l.append(list(t))\n","        return l\n","    def list_state_to_tuple(st):\n","        t = []\n","        for l in st:\n","            t.append(tuple(l))\n","        return tuple(t)\n","    \n","    if to_print:\n","        print(f\"Player 1: {player1.name} vs. Player 2: {player2.name}\")\n","        print(f\"Turn {turn}\")\n","        print_state(board_state)\n","        print('\\n')\n","    turn += 1\n","    # Loop until the game is over\n","    while not is_game_over:\n","        \n","        # Play a turn for player 1\n","        position = player1.play(board_state)\n","        # Update the board state\n","        board_state = tuple_state_to_list(board_state)\n","        board_state[math.floor(position / 3)][position % 3] = 1\n","        board_state = list_state_to_tuple(board_state)\n","        if to_print:\n","            print(f\"Turn {turn}, {player1.name}\")\n","            print_state(board_state)\n","            print('\\n')\n","        # Increment the turn counter\n","        turn += 1\n","        # Check if this is a win\n","        is_game_over = is_end(board_state)\n","        # If the game is over, break the loop\n","        if is_game_over:\n","            winner = 1\n","            if to_print:\n","                print(f\"{player1.name} wins!\")\n","            break\n","        \n","        # Play a turn for player 2\n","        \n","        # Check if the game is a draw\n","        # If there are no 0 values in the board state, the game is a draw\n","        if list(chain.from_iterable(tuple_state_to_list(board_state))).count(0) == 0:\n","            is_game_over = True\n","            winner = 0\n","            if to_print:\n","                print(\"The game is a draw!\")\n","            break\n","\n","        position = player2.play(board_state)\n","        # Update the board state\n","        board_state = tuple_state_to_list(board_state)\n","        board_state[math.floor(position / 3)][position % 3] = 2\n","        board_state = list_state_to_tuple(board_state)\n","        if to_print:\n","            print(f\"Turn {turn}, {player2.name}\")\n","            print_state(board_state)\n","            print('\\n')\n","        # Increment the turn counter\n","        turn += 1\n","        # Check if this is a win\n","        is_game_over = is_end(board_state)\n","        # If the game is over, break the loop\n","        if is_game_over:\n","            winner = 2\n","            if to_print:\n","                print(f\"{player2.name} wins!\")                \n","            break\n","\n","    # Resolve the game for both players\n","    if is_game_over:\n","        if winner == 1:\n","            player1.resolve_game('W')\n","            player2.resolve_game('L')\n","            winning_player = player1.name\n","        elif winner == 2:\n","            player1.resolve_game('L')\n","            player2.resolve_game('W')\n","            winning_player = player2.name\n","        else:\n","            player1.resolve_game('D')\n","            player2.resolve_game('D')\n","            winning_player = 'Draw'\n","\n","    if to_return_winner:\n","        return winning_player        "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Testing the engine"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We create two MenaceEngine objects that will play against each other."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["testEngineA = MenaceEngine(name = 'testEngineA')\n","testEngineB = MenaceEngine(name = 'testEngineB')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["And have them play one game."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player 1: testEngineA vs. Player 2: testEngineB\n","Turn 0\n","000\n","000\n","000\n","\n","\n","Turn 1, testEngineA\n","100\n","000\n","000\n","\n","\n","Turn 2, testEngineB\n","100\n","000\n","002\n","\n","\n","Turn 3, testEngineA\n","100\n","000\n","012\n","\n","\n","Turn 4, testEngineB\n","102\n","000\n","012\n","\n","\n","Turn 5, testEngineA\n","102\n","000\n","112\n","\n","\n","Turn 6, testEngineB\n","122\n","000\n","112\n","\n","\n","Turn 7, testEngineA\n","122\n","100\n","112\n","\n","\n","testEngineA wins!\n"]}],"source":["play_game(testEngineA, testEngineB, to_print = True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The played moves are not very intelligent as neither engine has been trained. Let's see if the TokenBags were updated as expected. The winners played moves should have been updated with more tokens and the loosers with fewer. Below we see what happened to the TokenBag for the first players first move (when the board was empty)."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 6, 1: 3, 2: 3, 3: 3, 4: 3, 5: 3, 6: 3, 7: 3, 8: 3}\n"]}],"source":["testEngineA.boxes.show_token_bag(1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We let the engines learn by playing each other for 100 games without printing the output. We then play one more game for which we print what happens."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player 1: testEngineB vs. Player 2: testEngineA\n","Turn 0\n","000\n","000\n","000\n","\n","\n","Turn 1, testEngineB\n","010\n","000\n","000\n","\n","\n","Turn 2, testEngineA\n","010\n","002\n","000\n","\n","\n","Turn 3, testEngineB\n","010\n","102\n","000\n","\n","\n","Turn 4, testEngineA\n","010\n","102\n","020\n","\n","\n","Turn 5, testEngineB\n","010\n","102\n","120\n","\n","\n","Turn 6, testEngineA\n","010\n","102\n","122\n","\n","\n","Turn 7, testEngineB\n","010\n","112\n","122\n","\n","\n","Turn 8, testEngineA\n","012\n","112\n","122\n","\n","\n","testEngineA wins!\n"]}],"source":["for i in range(100):\n","    play_game(testEngineA, testEngineB, to_print = False)\n","play_game(testEngineA, testEngineB, to_print = True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Still not very smart playing. We train for 1000 more games."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player 1: testEngineB vs. Player 2: testEngineA\n","Turn 0\n","000\n","000\n","000\n","\n","\n","Turn 1, testEngineB\n","000\n","000\n","010\n","\n","\n","Turn 2, testEngineA\n","000\n","200\n","010\n","\n","\n","Turn 3, testEngineB\n","000\n","200\n","011\n","\n","\n","Turn 4, testEngineA\n","000\n","220\n","011\n","\n","\n","Turn 5, testEngineB\n","000\n","221\n","011\n","\n","\n","Turn 6, testEngineA\n","002\n","221\n","011\n","\n","\n","Turn 7, testEngineB\n","002\n","221\n","111\n","\n","\n","testEngineB wins!\n"]}],"source":["for i in range(1000):\n","    play_game(testEngineA, testEngineB, to_print = False)\n","play_game(testEngineA, testEngineB, to_print = True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["That looks like a slightly more intelligently played game. The better the engines play, the more often the game should end in a draw. Let's play 100 games and see how often they draw."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["draws_and_games = [0,0]\n","for i in range(100):\n","    result = play_game(testEngineA, testEngineB, to_print = False, to_return_winner=True)\n","    draws_and_games[1] += 1\n","    if result == 'Draw':\n","        draws_and_games[0] += 1"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["29% of games end in a draw.\n"]}],"source":["print(f\"{(draws_and_games[0] / draws_and_games[1] * 100):.0f}% of games end in a draw.\") "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["If we train for another 1000 games the share of draws should increase."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["for i in range(1000):\n","    play_game(testEngineA, testEngineB, to_print = False)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["36% of games end in a draw.\n"]}],"source":["draws_and_games = [0,0]\n","for i in range(100):\n","    result = play_game(testEngineA, testEngineB, to_print = False, to_return_winner=True)\n","    draws_and_games[1] += 1\n","    if result == 'Draw':\n","        draws_and_games[0] += 1\n","print(f\"{(draws_and_games[0] / draws_and_games[1] * 100):.0f}% of games end in a draw.\") "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The original MENACE was said to be unbeatable after training for 150 games. These engines train more slowly probably because they play against another randomly playing engine. In addition, they play both first and second player while the match box MENACE only played first. If they would train against a optimally playing human, they would learn the most important positions first. Let's train for another 5000 games and calculate the share of draws again."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["for i in range(5000):\n","    play_game(testEngineA, testEngineB, to_print = False)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["78% of games end in a draw.\n"]}],"source":["draws_and_games = [0,0]\n","for i in range(100):\n","    result = play_game(testEngineA, testEngineB, to_print = False, to_return_winner=True)\n","    draws_and_games[1] += 1\n","    if result == 'Draw':\n","        draws_and_games[0] += 1\n","print(f\"{(draws_and_games[0] / draws_and_games[1] * 100):.0f}% of games end in a draw.\") "]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player 1: testEngineB vs. Player 2: testEngineA\n","Turn 0\n","000\n","000\n","000\n","\n","\n","Turn 1, testEngineB\n","001\n","000\n","000\n","\n","\n","Turn 2, testEngineA\n","001\n","020\n","000\n","\n","\n","Turn 3, testEngineB\n","001\n","021\n","000\n","\n","\n","Turn 4, testEngineA\n","001\n","021\n","002\n","\n","\n","Turn 5, testEngineB\n","101\n","021\n","002\n","\n","\n","Turn 6, testEngineA\n","121\n","021\n","002\n","\n","\n","Turn 7, testEngineB\n","121\n","021\n","012\n","\n","\n","Turn 8, testEngineA\n","121\n","021\n","212\n","\n","\n","Turn 9, testEngineB\n","121\n","121\n","212\n","\n","\n","The game is a draw!\n"]}],"source":["play_game(testEngineA, testEngineB, to_print = True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["That looks pretty good. We will now write a class that lets a human play against the engine."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["class HumanPlayer():\n","    def __init__(self, name):\n","        self.name = name\n","    def play(self, board_state):\n","        print(\"Enter a position (0-8):\")\n","        position = int(input())\n","        return position\n","    def resolve_game(self, result):\n","        pass"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player 1: I, the player vs. Player 2: testEngineA\n","Turn 0\n","000\n","000\n","000\n","\n","\n","Enter a position (0-8):\n","Turn 1, I, the player\n","100\n","000\n","000\n","\n","\n","Turn 2, testEngineA\n","100\n","002\n","000\n","\n","\n","Enter a position (0-8):\n","Turn 3, I, the player\n","100\n","002\n","100\n","\n","\n","Turn 4, testEngineA\n","102\n","002\n","100\n","\n","\n","Enter a position (0-8):\n","Turn 5, I, the player\n","102\n","002\n","101\n","\n","\n","Turn 6, testEngineA\n","102\n","202\n","101\n","\n","\n","Enter a position (0-8):\n","Turn 7, I, the player\n","102\n","202\n","111\n","\n","\n","I, the player wins!\n"]}],"source":["play_game(HumanPlayer('I, the player'), testEngineA, to_print = True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Here we create a new untrained MENACE and let it play against a trained engine."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["untrainedMENACE = MenaceEngine(name = 'untrainedMENACE')\n","untrainedMENACE.set_learning(False)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player 1: untrainedMENACE vs. Player 2: testEngineA\n","Turn 0\n","000\n","000\n","000\n","\n","\n","Turn 1, untrainedMENACE\n","000\n","001\n","000\n","\n","\n","Turn 2, testEngineA\n","000\n","001\n","200\n","\n","\n","Turn 3, untrainedMENACE\n","001\n","001\n","200\n","\n","\n","Turn 4, testEngineA\n","001\n","001\n","202\n","\n","\n","Turn 5, untrainedMENACE\n","001\n","101\n","202\n","\n","\n","Turn 6, testEngineA\n","001\n","121\n","202\n","\n","\n","Turn 7, untrainedMENACE\n","101\n","121\n","202\n","\n","\n","Turn 8, testEngineA\n","101\n","121\n","222\n","\n","\n","testEngineA wins!\n"]}],"source":["play_game(untrainedMENACE, testEngineA, to_print = True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["And we calculate what percentage of games the untrained MENACE wins. It should be very low."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The untrained engine wins 11% of games and 15% end in a draw.\n"]}],"source":["untrainedwins_and_games = [0,0,0]\n","for i in range(100):\n","    result = play_game(untrainedMENACE, testEngineA, to_print = False, to_return_winner=True)\n","    untrainedwins_and_games[2] += 1\n","    if result == 'untrainedMENACE':\n","        untrainedwins_and_games[0] += 1\n","    if result == 'Draw':\n","        untrainedwins_and_games[1] += 1\n","print(f\"The untrained engine wins {(untrainedwins_and_games[0] / untrainedwins_and_games[2] * 100):.0f}% \\\n","of games and {(untrainedwins_and_games[1] / untrainedwins_and_games[2] * 100):.0f}% end in a draw.\") "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["So the MENACE engine actually does work!"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNcYvOxZ3mlOceU17+0i0aJ","provenance":[{"file_id":"1A_M0FF1c0IvJA9N605s8V9WtLL8-5QyV","timestamp":1678694683718}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
